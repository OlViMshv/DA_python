{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcd1e5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in c:\\users\\olga_\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.13.0)\n",
      "Requirement already satisfied: blinker>=1.0.0 in c:\\users\\olga_\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from streamlit) (1.5)\n",
      "Requirement already satisfied: toml in c:\\users\\olga_\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: watchdog in c:\\users\\olga_\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from streamlit) (2.1.9)\n",
      "Requirement already satisfied: pympler>=0.9 in c:\\users\\olga_\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from streamlit) (1.0.1)\n",
      "Requirement already satisfied: gitpython!=3.1.19 in c:\\users\\olga_\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from streamlit) (3.1.27)\n",
      "Requirement already satisfied: pydeck>=0.1.dev5 in c:\\users\\olga_\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from streamlit) (0.8.0b3)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\olga_\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from streamlit) (8.1.3)\n",
      "Requirement already satisfied: requests>=2.4 in c:\\users\\olga_\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from streamlit) (2.28.1)\n",
      "Requirement already satisfied: cachetools>=4.0 in c:\\users\\olga_\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from streamlit) (5.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\olga_\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from streamlit) (1.23.3)\n",
      "Requirement already satisfied: pandas>=0.21.0 in c:\\users\\olga_\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from streamlit) (1.5.0)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in c:\\users\\olga_\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from streamlit) (4.12.0)\n",
      "Requirement already satisfied: tornado>=5.0 in c:\\users\\olga_\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from streamlit) (6.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\olga_\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from streamlit) (9.2.0)\n",
      "Requirement already satisfied: protobuf!=3.20.2,<4,>=3.12 in c:\\users\\olga_\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from streamlit) (3.20.1)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in c:\\users\\olga_\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from streamlit) (4.3.0)\n",
      "Requirement already satisfied: altair>=3.2.0 in c:\\users\\olga_\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from streamlit) (4.2.0)\n",
      "Requirement already satisfied: validators>=0.2 in c:\\users\\olga_\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from streamlit) (0.20.0)\n",
      "Requirement already satisfied: packaging>=14.1 in c:\\users\\olga_\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from streamlit) (21.3)\n",
      "Requirement already satisfied: tzlocal>=1.1 in c:\\users\\olga_\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from streamlit) (4.2)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\olga_\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from streamlit) (2.8.2)\n",
      "Requirement already satisfied: semver in c:\\users\\olga_\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from streamlit) (2.13.0)\n",
      "Requirement already satisfied: pyarrow>=4.0 in c:\\users\\olga_\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from streamlit) (9.0.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\olga_\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from streamlit) (12.5.1)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\olga_\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from altair>=3.2.0->streamlit) (0.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\olga_\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from altair>=3.2.0->streamlit) (3.1.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\olga_\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from altair>=3.2.0->streamlit) (4.16.0)\n",
      "Requirement already satisfied: toolz in c:\\users\\olga_\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from altair>=3.2.0->streamlit) (0.12.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\olga_\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from click>=7.0->streamlit) (0.4.5)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\olga_\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gitpython!=3.1.19->streamlit) (4.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\olga_\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from importlib-metadata>=1.4->streamlit) (3.8.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\olga_\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging>=14.1->streamlit) (3.0.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\olga_\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=0.21.0->streamlit) (2022.2.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\olga_\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil->streamlit) (1.16.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\olga_\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.4->streamlit) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\olga_\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.4->streamlit) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\olga_\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.4->streamlit) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\olga_\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.4->streamlit) (2022.9.24)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in c:\\users\\olga_\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rich>=10.11.0->streamlit) (2.13.0)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in c:\\users\\olga_\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rich>=10.11.0->streamlit) (0.9.1)\n",
      "Requirement already satisfied: pytz-deprecation-shim in c:\\users\\olga_\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tzlocal>=1.1->streamlit) (0.1.0.post0)\n",
      "Requirement already satisfied: tzdata in c:\\users\\olga_\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tzlocal>=1.1->streamlit) (2022.4)\n",
      "Requirement already satisfied: decorator>=3.4.0 in c:\\users\\olga_\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from validators>=0.2->streamlit) (5.1.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\olga_\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19->streamlit) (5.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\olga_\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->altair>=3.2.0->streamlit) (2.1.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\olga_\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit) (22.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\olga_\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit) (0.18.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdd18a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83f94baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7188b0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\l2_text_tfidf.ipynb\n",
      ".\\test.csv\n",
      ".\\train.csv\n",
      ".\\Задание2.ipynb\n",
      ".\\.ipynb_checkpoints\\l2_text_tfidf-checkpoint.ipynb\n",
      ".\\.ipynb_checkpoints\\Задание2-checkpoint.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    " \n",
    "# выводим пути к папкам (dirpath) и наименования файлов (filenames) и после этого\n",
    "for dirpath, _, filenames in os.walk('.'):\n",
    "  \n",
    "  # во вложенном цикле проходимся по названиям файлов\n",
    "  for filename in filenames:\n",
    " \n",
    "    # и соединяем путь до папок и входящие в эти папки файлы\n",
    "    # с помощью метода path.join()\n",
    "    print(os.path.join(dirpath, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02a64fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1915de90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>На нас обиделась Оля....Жизнь потеряла смысл. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @PolinaZuzy: http://t.co/ZYwbUowIti единств...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@AHamueva Машину назвать малышкой,мать ты ебу ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @malina23_: отличный день в школе!:*теперь ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Serebryakovaaa не то слово))) у него что ни м...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  На нас обиделась Оля....Жизнь потеряла смысл. ...      0\n",
       "1  RT @PolinaZuzy: http://t.co/ZYwbUowIti единств...      1\n",
       "2  @AHamueva Машину назвать малышкой,мать ты ебу ...      1\n",
       "3  RT @malina23_: отличный день в школе!:*теперь ...      1\n",
       "4  @Serebryakovaaa не то слово))) у него что ни м...      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b24f1f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.replace('/','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef2d9102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция удаления пунктуации и цифр\n",
    "def remove_trash(list): \n",
    "    pattern = '[^А-Яа-я0-9]+'\n",
    "    try:\n",
    "      list = [re.sub(pattern, ' ', i) for i in list] \n",
    "      print (list)\n",
    "    except Exception as e:\n",
    "      print(e)\n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4628dabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df['text_clean'] = remove_trash(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00056975",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df.text_clean.isna()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "148fa9ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136100, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c02bcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd22fec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_russian = stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "682513c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_russian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e5d300e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_transformer = TfidfVectorizer(stop_words=stop_russian, ngram_range=(1,1), lowercase=True, max_features=15000 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc7e4ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>136095</th>\n",
       "      <td>А Зоя и Рита Шабановы все-таки сучки.   Р.S. М...</td>\n",
       "      <td>1</td>\n",
       "      <td>А Зоя и Рита Шабановы все таки сучки Р Маринка...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136096</th>\n",
       "      <td>@nvarlygina я все пропустила!:( ну хоть ты заг...</td>\n",
       "      <td>0</td>\n",
       "      <td>я все пропустила ну хоть ты загадала и надеюс...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136097</th>\n",
       "      <td>RT @milkiwey_: выходные были хорошими, даже яр...</td>\n",
       "      <td>1</td>\n",
       "      <td>выходные были хорошими даже яркими очень</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136098</th>\n",
       "      <td>@leshqa_meow ахахах, ну ты же стааарше меня, м...</td>\n",
       "      <td>1</td>\n",
       "      <td>ахахах ну ты же стааарше меня мне нужна подде...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136099</th>\n",
       "      <td>Пришла к прабабушке, она мне говорит с кем ты ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Пришла к прабабушке она мне говорит с кем ты т...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  label  \\\n",
       "136095  А Зоя и Рита Шабановы все-таки сучки.   Р.S. М...      1   \n",
       "136096  @nvarlygina я все пропустила!:( ну хоть ты заг...      0   \n",
       "136097  RT @milkiwey_: выходные были хорошими, даже яр...      1   \n",
       "136098  @leshqa_meow ахахах, ну ты же стааарше меня, м...      1   \n",
       "136099  Пришла к прабабушке, она мне говорит с кем ты ...      0   \n",
       "\n",
       "                                               text_clean  \n",
       "136095  А Зоя и Рита Шабановы все таки сучки Р Маринка...  \n",
       "136096   я все пропустила ну хоть ты загадала и надеюс...  \n",
       "136097          выходные были хорошими даже яркими очень   \n",
       "136098   ахахах ну ты же стааарше меня мне нужна подде...  \n",
       "136099  Пришла к прабабушке она мне говорит с кем ты т...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae95ff5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text_transformer.fit_transform(df['text_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97dd4f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Офигенный день!\\nдень позитива)\\nбегал как идиот целый день!\\nтанцы офигенны, хоть я и ракал но мне очень понравилось!                                                  96\n",
       "RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретвит((((( RT                                                                                                                 62\n",
       "sm&amp;gt; напомни, как называется: фотка, вокруг черная рамка, а внизу - надпись?\\nau&amp;gt; некролог?\\nsm&amp;gt; не.. (\\nau&amp;gt; демотиватор?\\nsm&amp;gt; ДА!    43\n",
       "RT @Creative_Link: Дождались! Официальный трейлер \"Иван Царевич и Серый Волк - 2\". Смотреть всем: http:t.cogmelSGMIuW Толи еще будет)                                   42\n",
       "RT @Podslyshano: люблю зиму за то, что люди носом разблокируют телефоны, и такие оглядываются типа без палева)) а я то все вижу. да да.                                 35\n",
       "                                                                                                                                                                        ..\n",
       "День просто супер,в футбол выиграли у вояк,в волейбол выиграл,там и там чуть-чуть на забивал,скоро идем с парнишами отдыхать )))..                                       1\n",
       "Смотрю на погоду и невольно вырывается так: это Питер, детка! Но потом понимаю, что я в екб( #питер # екб #2014                                                          1\n",
       "RT @El6kin: Поклон звонарю с Михайловского!)\\n#євромайдан                                                                                                                1\n",
       "@vikylya__ я просто в последние 2 дня почти не заходил сюда:|                                                                                                            1\n",
       "Пришла к прабабушке, она мне говорит с кем ты там по интернету познакомилась. Бабушка ей уже что то наплела, а ведь сама ничего не знает:(                               1\n",
       "Name: text, Length: 131879, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3f986ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(text, df['text'], test_size=0.3, random_state=1912)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "628bcbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95270, 15000) (40830, 15000)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94801e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2dd13d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdb657a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca21e8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388bf5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc53e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Качество модели по метрике F1', sklearn.metrics.f1_score(y_test,pred,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0239fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37fe963",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time #првоерить время выполнения функции\n",
    "# функция лемматизации - приводит в 1 форму\n",
    "def lemmatize(row):\n",
    "    t = []\n",
    "    text = row['text_clean']\n",
    "    for word in text.split():\n",
    "        if len(word)<=3:   #удаляет слова, которые меньше == 3 символа\n",
    "            continue\n",
    "        p = morph.parse(word)[0]\n",
    "        t.append(p.normal_form)\n",
    "    return \" \".join(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78ce990",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['text_clean_normal'] = df.apply(lemmatize,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f90865",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['text_clean','text_clean_normal']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968c2c35",
   "metadata": {},
   "source": [
    "### качество модели после лемматизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c0d31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_norm = text_transformer.fit_transform(df['text_clean_normal'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(text_norm, df['topic_label'], test_size=0.3, random_state=1912)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855b698f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_norm = tree.DecisionTreeClassifier()\n",
    "clf_norm.fit(X_train,y_train)\n",
    "pred_norm = clf_norm.predict(X_test)\n",
    "print('Качество модели по метрике F1 после лемматизации', sklearn.metrics.f1_score(y_test,pred_norm,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef17231b-f3ae-448d-b926-e7760c05d556",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
